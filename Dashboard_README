# Dashboard Overview

The `dashboard_monitor.py` Streamlit app surfaces key health and performance indicators from the SQLite monitoring database. Metrics fall into two groups: **Data Quality & Drift** and **Model Performance & Trading**.

## Data Quality and Drift KPIs
These metrics assess input data integrity and feature distribution stability.

| KPI | Description | Page Location |
| --- | --- | --- |
| **Missing Bars %** | Percentage of expected time-series bars (e.g., 4-hour bars) missing in the latest monitoring period. | Overview, Drilldown |
| **Outlier Bars %** | Percentage of bars flagged as outliers in the latest data, signaling potential data drift. | Drilldown |
| **Drift Flag** | Categorical status ("OK", "WARN", "ACTION") derived from data quality and feature/prediction drift checks. | Overview, Drilldown |

## Model Performance and Trading KPIs
These metrics evaluate live or proxy trading effectiveness using a holdout/production-proxy period.

| KPI | Description | Page Location |
| --- | --- | --- |
| **Expectancy Net (proxy)** | Average forward return (net of transaction costs, if applied) realized on signals generated by the model in the holdout period. | Overview, Drilldown |
| **Profit Factor (PF) (proxy)** | Ratio of gross profit to gross loss on signals: \(PF = \frac{\sum \text{Positive Returns}}{\sum \text{Negative Returns}}\). | Overview, Drilldown |
| **WARN/ACTION Count** | Count of tickers whose latest Drift Flag is "WARN" or "ACTION". | Overview |

## Most Important KPIs to Watch
The following KPIs give the clearest signal of real-world degradation.

- **Drift Flag / WARN/ACTION Count (Primary)**
  - *Why*: Summary status of data and model health; an "ACTION" requires immediate investigation or retraining.
  - *Watch for*: Any nonzero WARN/ACTION count on the Overview, or an ACTION status on Drilldown.
- **Expectancy Net (proxy) (Primary)**
  - *Why*: Direct profitability per signal. Values near/below zero imply the model is losing money on average.
  - *Watch for*: Downward trends on Overview/Drilldown, or values near/below zero.
- **Missing Bars % (Secondary)**
  - *Why*: High missing bars indicate data ingestion/provider issues that can bias training or predictions.
  - *Watch for*: Sudden spikes or persistent elevation on Overview/Drilldown.
- **Profit Factor (proxy) (Secondary)**
  - *Why*: Complements Expectancy; PF below ~1.5 suggests winners do not sufficiently outweigh losers.
  - *Watch for*: Significant decline from expected PF baseline.

## Model Registry Metrics
The Model Registry section tracks KPIs captured during training and cross-validation (CV).

### Training and CV Metrics
These originate from `wfo_metrics_json` (walk-forward/CV summary) and `holdout_metrics_json` prior to deployment.

| Metric | Source Key | Description | Importance |
| --- | --- | --- | --- |
| **Precision** | `cv_summary.get('precision')` | Ratio of true positives to all predicted positives; primary optimization target. | Primary |
| **Profit Factor Proxy** | `cv_summary.get('profit_factor_proxy')` | Ratio of total positive to total absolute negative forward returns across CV folds; indicates risk-adjusted profitability. | Primary |
| **Expectancy Proxy** | `cv_summary.get('expectancy_proxy')` | Average forward return per signaled trade during CV. | Secondary |
| **Signals/Fold** | `cv_summary.get('signals')` | Average number of predicted positive signals per CV fold; monitors signal frequency. | Secondary |
| **ROC-AUC** | `cv_summary.get('roc_auc')` | Ability to discriminate positives vs negatives across thresholds. | Secondary |

### Registry KPIs to Watch
- **Precision (CV Summary) (Primary)**
  - *Why*: Training objective prioritizes precision; drops imply unreliable trade signals.
  - *Watch for*: New model versions with materially lower precision than predecessors.
- **Profit Factor Proxy (CV Summary) (Primary)**
  - *Why*: High PF (e.g., >1.5) signals profitable balance between winners and losers during backtests.
  - *Watch for*: PF below profitable threshold (e.g., <1.0).
- **Holdout Metrics (Primary)**
  - *Why*: Final unbiased check on unseen data before deployment.
  - *Watch for*: Significant performance degradation (e.g., PF < 1.0) relative to CV summary metrics.

